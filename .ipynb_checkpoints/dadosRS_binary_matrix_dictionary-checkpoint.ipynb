{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 962,
     "status": "ok",
     "timestamp": 1601510867245,
     "user": {
      "displayName": "Leonardo Nunes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKqaYTRJ_Ypghz8sEyulGVoqkiIWzYPxawtqg=s64",
      "userId": "08647340071524651515"
     },
     "user_tz": 180
    },
    "id": "XbPDzHOrc3ME"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1601510868207,
     "user": {
      "displayName": "Leonardo Nunes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKqaYTRJ_Ypghz8sEyulGVoqkiIWzYPxawtqg=s64",
      "userId": "08647340071524651515"
     },
     "user_tz": 180
    },
    "id": "65PaawDZdImD"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"header_binary_matrix.csv\")\n",
    "list_df = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1601510921194,
     "user": {
      "displayName": "Leonardo Nunes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKqaYTRJ_Ypghz8sEyulGVoqkiIWzYPxawtqg=s64",
      "userId": "08647340071524651515"
     },
     "user_tz": 180
    },
    "id": "5V65I9Azdu15"
   },
   "outputs": [],
   "source": [
    "dic = {}\n",
    "\n",
    "for i in range(len(list_df)):\n",
    "  dic[i] = list_df[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 57
    },
    "executionInfo": {
     "elapsed": 931,
     "status": "ok",
     "timestamp": 1601510924379,
     "user": {
      "displayName": "Leonardo Nunes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhKqaYTRJ_Ypghz8sEyulGVoqkiIWzYPxawtqg=s64",
      "userId": "08647340071524651515"
     },
     "user_tz": 180
    },
    "id": "xRDa3GQffGEo",
    "outputId": "2fc91508-b465-4207-bf61-e811860b516a"
   },
   "outputs": [],
   "source": [
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {0: 'SexF', 1: 'SexM', 2: 'Bebe', 3: 'Crianca', 4: 'Jovem', 5: 'Adulto', 6: 'Idoso', 7: 'Muito_idoso', \n",
    "           8: 'Conf_Fev', 9: 'Conf_Mar', 10: 'Conf_Abr', 11: 'Conf_Mai', 12: 'Conf_Jun', 13: 'Conf_Jul', 14: 'Conf_Ago', \n",
    "           15: 'Conf_Set', 16: 'Sint_Fev', 17: 'Sint_Mar', 18: 'Sint_Abr', 19: 'Sint_Mai', 20: 'Sint_Jun', 21: 'Sint_Jul', \n",
    "           22: 'Sint_Ago', 23: 'Sint_Set', 24: 'Evo_Rec', 25: 'Evo_Obito', 26: 'Evo_Aco', 27: 'Hosp_S', 28: 'Hosp_N', \n",
    "           29: 'Febre_S', 30: 'Febre_N', 31: 'Tosse_S', 32: 'Tosse_N', 33: 'Garganta_S', 34: 'Garganta_N', 35: 'Dispneia_S', \n",
    "           36: 'Dispneia_N', 37: 'Asma_S', 38: 'Asma_N', 39: 'DRespiratoria_S', 40: 'DRespiratoria_N', 41: 'DNeurologia_S', \n",
    "           42: 'DNeurologia_N', 43: 'Diabetes_S', 44: 'Diabetes_N', 45: 'Imunodef_S', 46: 'Imunodef_N', 47: 'DRenal_S', \n",
    "           48: 'DRenal_N', 49: 'DHepatica_S', 50: 'DHepatica_N', 51: 'DCardiaca_S', 52: 'DCardiaca_N', 53: 'Obesidade_S', \n",
    "           54: 'Obesidade_N'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = \"./output_clustering/covid1_res_k2.txt\"\n",
    "# file = \"./output_clustering/covid1_res_k3.txt\"\n",
    "# file = \"./output_clustering/covid1_res_k4.txt\"\n",
    "# file = \"./output_clustering/covid1_res_k5.txt\"\n",
    "file = \"./output_clustering/covid1_res_k6.txt\"\n",
    "df_fimi = pd.read_csv(file, header=None, names=[\"transation\"])\n",
    "columnClusters,rowClusters = processDocument(df_fimi)\n",
    "del df_fimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_result(columnClusters,rowClusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-clustering methods - scikit-learn\n",
    "1) https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster\n",
    "\n",
    "2) https://scikit-learn.org/stable/modules/biclustering.html#biclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"Toy1_b4_binary_forcocluster.dat\"\n",
    "path1 = './input_datasets/'+file1\n",
    "file2 = \"Toy1_b4_binary_fortraditional.dat\"\n",
    "path2 = './input_datasets/'+file2\n",
    "\n",
    "df = pd.read_csv(path1,header=None)\n",
    "df2 = pd.read_csv(path2,header=None)\n",
    "data = df.values.copy()\n",
    "data2 = df2.values.copy()\n",
    "print(data.shape)\n",
    "print(data2.shape)\n",
    "\n",
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(14,8))\n",
    "fig.figsize = (19,19)\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.matshow(data, cmap=plt.cm.Blues)\n",
    "ax1.matshow(data, cmap=plt.cm.Blues,aspect=\"auto\")\n",
    "#plt.title(\"Binary dataset for co-clusters\")\n",
    "ax1.set_title(\"Binary dataset for co-clusters\")\n",
    "\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.matshow(data2, cmap=plt.cm.Blues)\n",
    "ax2.matshow(data2, cmap=plt.cm.Blues,aspect=\"auto\")\n",
    "#plt.title(\"Binary dataset for traditional methods\")\n",
    "ax2.set_title(\"Binary dataset for traditional methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster.bicluster import SpectralCoclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "1.1\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "0.10\n",
      "1.2\n",
      "0.11\n",
      "0.12\n",
      "0.13\n",
      "0.14\n",
      "0.15\n",
      "1.3\n",
      "0.16\n",
      "0.17\n",
      "1.4\n",
      "0.18\n",
      "0.19\n",
      "0.20\n",
      "1.5\n",
      "0.21\n",
      "1.6\n",
      "1.7\n",
      "0.22\n",
      "0.23\n",
      "1.8\n",
      "0.24\n",
      "1.9\n",
      "0.25\n",
      "1.10\n",
      "0.26\n",
      "1.11\n",
      "0.27\n",
      "1.12\n",
      "0.28\n",
      "1.13\n",
      "0.29\n",
      "1.14\n",
      "0.30\n",
      "1.15\n",
      "0.31\n",
      "1.16\n",
      "0.32\n",
      "1.17\n",
      "0.33\n",
      "1.18\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('input_datasets/input_new.csv', sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ricardogiuliani/anaconda3/lib/python3.7/site-packages/sklearn/cluster/_bicluster.py:36: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  col_diag = np.asarray(1.0 / np.sqrt(X.sum(axis=0))).squeeze()\n",
      "/Users/ricardogiuliani/anaconda3/lib/python3.7/site-packages/sklearn/cluster/_bicluster.py:45: RuntimeWarning: invalid value encountered in multiply\n",
      "  an = row_diag[:, np.newaxis] * X * col_diag\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-18a04f6d58f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mDhillonCocluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpectralCoclustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mDhillonCocluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/_bicluster.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/_bicluster.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mnormalized_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_diag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_scale_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mn_sv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_discard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         z = np.vstack((row_diag[:, np.newaxis] * u,\n\u001b[1;32m    295\u001b[0m                        col_diag[:, np.newaxis] * v))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/cluster/_bicluster.py\u001b[0m in \u001b[0;36m_svd\u001b[0;34m(self, array, n_components, n_discard)\u001b[0m\n\u001b[1;32m    132\u001b[0m             u, _, vt = randomized_svd(array, n_components,\n\u001b[1;32m    133\u001b[0m                                       \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                                       **kwargs)\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'arpack'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     Q = randomized_range_finder(M, n_random, n_iter,\n\u001b[0;32m--> 348\u001b[0;31m                                 power_iteration_normalizer, random_state)\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;31m# project M to the (k + p) dimensional space using the basis vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LU'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'QR'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/linalg/decomp_lu.py\u001b[0m in \u001b[0;36mlu\u001b[0;34m(a, permute_l, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         raise ValueError(\n\u001b[0;32m--> 499\u001b[0;31m             \"array must not contain infs or NaNs\")\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "clusters = 6\n",
    "DhillonCocluster = SpectralCoclustering(n_clusters = clusters, random_state = 0)\n",
    "DhillonCocluster.fit(data)\n",
    "\n",
    "    \n",
    "reconstructed_matrix = np.zeros(data.shape,dtype=int)\n",
    "for nc in range(clusters):\n",
    "    if len(DhillonCocluster.get_indices(nc)[0]) != 0 and len(DhillonCocluster.get_indices(nc)[1]) != 0:\n",
    "        for i in DhillonCocluster.get_indices(nc)[0]:#Indices of rows in the dataset that belong to the bicluster.\n",
    "            for j in DhillonCocluster.get_indices(nc)[1]:#Indices of columns in the dataset that belong to the bicluster.\n",
    "                reconstructed_matrix[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , (ax1,ax2) = plt.subplots(1,2, figsize=(14,8))\n",
    "fig.figsize = (19,19)\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.matshow(data, cmap=plt.cm.Blues)\n",
    "ax1.matshow(data, cmap=plt.cm.Blues,aspect=\"auto\")\n",
    "#plt.title(\"Binary dataset for co-clusters\")\n",
    "ax1.set_title(\"Binary dataset for co-clusters\")\n",
    "\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.matshow(data2, cmap=plt.cm.Blues)\n",
    "ax2.matshow(reconstructed_matrix, cmap=plt.cm.Blues,aspect=\"auto\")\n",
    "#plt.title(\"Binary dataset for traditional methods\")\n",
    "ax2.set_title(\"Dhillon output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(columnClusters,rowClusters):\n",
    "    nc = len(columnClusters)\n",
    "    for i in range(nc):\n",
    "        num_objects = len(set(rowClusters[i]))\n",
    "        print(\"Cluster-\"+str(i+1)+\" (\"+str(num_objects)+\")\")\n",
    "        print(\"Atributos: \",end=\"\")\n",
    "        for ele in columnClusters[i]:\n",
    "            print(my_dict[int(ele)],end=\", \")\n",
    "\n",
    "        print(\"\\nSobreposição de OBJETOS em outros clusters.\")\n",
    "        for j in range(nc):\n",
    "            if i != j:\n",
    "                print(\"    Cluster \"+str(j+1)+\": \",end=\"\")\n",
    "#                 clusB = len(set(rowClusters[i]))\n",
    "                qtd_intersect = len(set(rowClusters[j]).intersection(set(rowClusters[i])))\n",
    "#                 overlap = ((num_objects-(num_objects-qtd_intersect))/len(set(rowClusters[i]).union(set(rowClusters[j]))))*100\n",
    "                overlap = ((num_objects-(num_objects-qtd_intersect))/num_objects)*100\n",
    "#                 overlap = ((cluSize-(cluSize-qtd_intersect)))*100\n",
    "                print(\"{0:.2f}% ({1:d})\".format(overlap,qtd_intersect))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FhmK3myQfY84"
   },
   "outputs": [],
   "source": [
    "def processDocument(file):\n",
    "    #print(\"Executing processDocument() method.\")\n",
    "    size_df = file.shape\n",
    "    uniqueP = []\n",
    "    uniqueT = []\n",
    "    pois_per_cluster = []\n",
    "    trajs_per_cluster = []\n",
    "    change = 0\n",
    "    \n",
    "    for i in range(size_df[0]):#number of transations\n",
    "        transationString = file.transation[i].split(' ')\n",
    "#         print(transationString)\n",
    "        pois = []\n",
    "        trajs = []\n",
    "        for j in range(len(transationString)):\n",
    "            try:\n",
    "                tmp = int(transationString[j])\n",
    "            except:\n",
    "                tmp = ''\n",
    "            \n",
    "            if change == 0:\n",
    "                if type(tmp) is int:\n",
    "                    if transationString[j] not in uniqueP:\n",
    "                        uniqueP.append(transationString[j])\n",
    "#                         if not pois: # empty\n",
    "                    pois.append(transationString[j])\n",
    "#                         print(transationString[j],end=\"|\")\n",
    "                else:\n",
    "    #                 print(\"NO\",end=\" | \")\n",
    "                    change = 1\n",
    "#                     print(\"\")\n",
    "            else:\n",
    "                if type(tmp) is int:\n",
    "                    if transationString[j] not in uniqueT:\n",
    "                        uniqueT.append(transationString[j])\n",
    "                    trajs.append(transationString[j])\n",
    "                else:\n",
    "    #                 print(\"NO\",end=\" | \")\n",
    "                    if change == 1:\n",
    "                        change = 2\n",
    "                        tmp = re.split('\\[| |\\]',transationString[j])\n",
    "                        #print(\"1-tmp:\"+str(tmp))\n",
    "                        if tmp[1] not in uniqueT:\n",
    "                            uniqueT.append(tmp[1])\n",
    "                        trajs.append(tmp[1])\n",
    "                    else:\n",
    "                        tmp = re.split('\\[| |\\]',transationString[j])\n",
    "                        #print(\"2-tmp:\"+str(tmp))\n",
    "                        if tmp[0] not in uniqueT:\n",
    "                            uniqueT.append(tmp[0])\n",
    "                        trajs.append(tmp[0])\n",
    "                        change = 0\n",
    "        pois_per_cluster.append(pois)\n",
    "        trajs_per_cluster.append(trajs)\n",
    "\n",
    "#     print('Number of unique elements: ',len(uniqueElements))\n",
    "#     print(\"P per Clusters: \"+str(pois_per_cluster))\n",
    "#     print(\"T per Clusters: \"+str(trajs_per_cluster))\n",
    "    return pois_per_cluster,trajs_per_cluster"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPNsa7FJlYOyi8nKkzIpu2Z",
   "collapsed_sections": [],
   "name": "dadosRS_binary_matrix_dictionary",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
